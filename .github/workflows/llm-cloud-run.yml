name: Gemini-LLM GCS Artifact Test

on:
  workflow_dispatch:
    inputs:
      seed_notes:
        description: "Seed notes.json into BigQuery before analysis"
        required: false
        type: boolean
        default: false
      use_prod_service_url:
        description: "Call the Cloud Run service after downloading artifacts"
        required: false
        type: boolean
        default: false
      prompt_file:
        description: "Select a prompt to use for analysis"
        required: true
        default: "multi-analyze.txt"
        type: choice
        options:
          - multi-analyze.txt

permissions:
  contents: read

env:
  GCP_PROJECT_ID: moz-mobile-tools
  SERVICE_URL: ${{ secrets.LLM_PROD_SERVICE_URL }}
  CRASH_URI: gs://testops-llm-artifacts/crashes/minidumps/examples/crash_example.txt
  ANR_URI: gs://testops-llm-artifacts/anr/examples/anr_example.txt
  IMG_URI: gs://testops-llm-artifacts/images/examples/iOS/1.png
  LOCAL_ARTIFACT_DIR: artifacts

jobs:
  seed-notes:
    if: ${{ inputs.seed_notes == true }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: pip install -r llm-cloud-run/requirements.txt

      - name: Authenticate to Google Cloud (JSON key)
        uses: google-github-actions/auth@v3
        with:
          credentials_json: ${{ secrets.GCP_SA_VERTEX_AI }}

      - name: Seed notes into BigQuery
        working-directory: llm-cloud-run
        env:
          GCP_PROJECT: moz-mobile-tools
          BQ_PROJECT: moz-mobile-tools
          BQ_DATASET: vertex_ai_tool
        run: python seed_notes.py

  manual-run:
    needs: [seed-notes]
    # Always run this job, even when seed-notes is skipped
    if: ${{ always() && !failure() && !cancelled() }}
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v6

      - name: Authenticate to Google Cloud (JSON key)
        uses: google-github-actions/auth@v3
        with:
          credentials_json: ${{ secrets.GCP_SA_VERTEX_AI }}

      - name: Setup gcloud
        uses: google-github-actions/setup-gcloud@v3
        with:
          project_id: ${{ env.GCP_PROJECT_ID }}

      - name: Set gcloud project (quiet)
        run: |
          gcloud --quiet config set project "$GCP_PROJECT_ID"

      - name: Download artifacts from GCS
        run: |
          mkdir -p "${LOCAL_ARTIFACT_DIR}"
          gcloud storage cp "${CRASH_URI}" "${LOCAL_ARTIFACT_DIR}/crash_example.txt"
          gcloud storage cp "${ANR_URI}" "${LOCAL_ARTIFACT_DIR}/anr_example.txt"
          gcloud storage cp "${IMG_URI}" "${LOCAL_ARTIFACT_DIR}/1.png"
          echo "Downloaded files:"
          ls -la "${LOCAL_ARTIFACT_DIR}"

      - name: (Optional) POST artifacts as JSON to Cloud Run
        if: ${{ inputs.use_prod_service_url == true }}
        run: |
          set -euo pipefail

          CRASH_FILE="${LOCAL_ARTIFACT_DIR}/crash_example.txt"
          ANR_FILE="${LOCAL_ARTIFACT_DIR}/anr_example.txt"
          IMG_FILE="${LOCAL_ARTIFACT_DIR}/1.png"

          TOKEN="$(gcloud auth print-identity-token --audiences="${SERVICE_URL}")"

          PROMPT_FILE=".github/prompts/${{ inputs.prompt_file }}"
          PROMPT=$(<"$PROMPT_FILE")

          # Write combined crash + ANR content to a temp file
          CONTENT_FILE="$(mktemp)"
          {
            printf 'Crash:\n'
            cat "$CRASH_FILE"
            printf '\n\nANR:\n'
            cat "$ANR_FILE"
          } > "$CONTENT_FILE"

          # Post multipart form data: prompt, content (from file), and image
          RESPONSE_FILE="$(mktemp)"
          curl --fail-with-body -sS -X POST \
            -H "Authorization: Bearer ${TOKEN}" \
            -F "prompt=$(printf "%s" "$PROMPT")" \
            -F "content=<${CONTENT_FILE};type=text/plain; charset=utf-8" \
            -F "image=@${IMG_FILE};type=image/png" \
            -o "$RESPONSE_FILE" \
            "${SERVICE_URL}/analyze"

          # Extract output from JSON response and write to GitHub summary
          OUTPUT=$(jq -r '.output' "$RESPONSE_FILE")

          {
            echo "### ðŸ§  LLM Analysis Summary"
            echo ""
            echo "$OUTPUT"
          } >> "$GITHUB_STEP_SUMMARY"


          rm -f "$CONTENT_FILE" "$RESPONSE_FILE"